# Process Reward Models That Think

<div align="center">

[![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)]([https://arxiv.org/abs/2504.16828](https://arxiv.org/abs/2504.16828))  [![Github](https://img.shields.io/badge/ThinkPRM-000000?style=for-the-badge&logo=github&logoColor=000&logoColor=white)]([https://github.com/mukhal/thinkprm](https://github.com/mukhal/thinkprm))



<div align="center" style="font-family: Arial, sans-serif;">
  <p>
    <a href="#news" style="text-decoration: none; font-weight: bold;">ðŸŽ‰ News</a> â€¢
    <a href="#introduction" style="text-decoration: none; font-weight: bold;">ðŸ“– Introduction</a>
  </p>
  <p>
    <a href="#getting-started" style="text-decoration: none; font-weight: bold;">âœ¨ Getting Started</a> â€¢
    <a href="#citation" style="text-decoration: none; font-weight: bold;">ðŸŽˆ Citation</a>
  </p>
</div>

</div>

# ðŸŽ‰News

- **[2025-04-23]** Our [paper](https://arxiv.org/abs/2504.16828) is released on arxiv.

# ðŸ“–Introduction

We introduce ThinkPRM, a collection of generative long CoT process reward models. ThinkPRM verifiers are trained using 1K synthetic verification CoTs that are filtered based on only on 8K process labels from PRM800K. 


# âœ¨Getting Started

*Code is coming soon.*


# ðŸŽˆCitation
If you find ThinkPRM helpful, please cite us.

```bibtex
@misc{khalifa2025,
      title={Process Reward Models That Think}, 
      author={Muhammad Khalifa and Rishabh Agarwal and Lajanugen Logeswaran and Jaekyeom Kim and Hao Peng and Moontae Lee and Honglak Lee and Lu Wang},
      year={2025},
      eprint={2504.16828},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2504.16828}, 
}
```
